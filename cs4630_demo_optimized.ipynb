{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8f4fc5",
   "metadata": {},
   "source": [
    "# NBA Predictions — Optimized Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 1) Setup & Install (minimal) ===\n",
    "!pip -q install nba_api pytz xgboost==2.0.3 scikit-learn pandas numpy joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 2) Configuration ===\n",
    "import os\n",
    "\n",
    "# Historical merged games CSV (2010+), must include columns:\n",
    "# date, home_team, away_team, home_points, away_points\n",
    "HIST_CSV = \"/content/nba_games_with_odds_2010on.csv\"  # change if needed\n",
    "\n",
    "# Team-only (no sportsbook lines) artifacts\n",
    "TEAM_FEATS_CSV = \"/content/team_only_feature_list.csv\"\n",
    "TEAM_LR_PATH   = \"/content/team_only_lr_cal.joblib\"\n",
    "TEAM_RF_PATH   = \"/content/team_only_rf_cal.joblib\"\n",
    "TEAM_XGB_PATH  = \"/content/team_only_xgb_cal.joblib\"\n",
    "\n",
    "# With-lines (market-aware) artifacts\n",
    "LINES_FEATS_CSV = \"/content/with_lines_orflag_feature_list.csv\"\n",
    "LINES_LR_PATH   = \"/content/with_lines_orflag_lr_cal.joblib\"\n",
    "LINES_RF_PATH   = \"/content/with_lines_orflag_rf_cal.joblib\"\n",
    "LINES_XGB_PATH  = \"/content/with_lines_orflag_xgb_cal.joblib\"\n",
    "\n",
    "# Odds API (optional for live odds)\n",
    "# Set once: os.environ['ODDS_API_KEY'] = 'YOUR_KEY'\n",
    "ODDS_API_KEY = os.getenv(\"ODDS_API_KEY\", \"\").strip()\n",
    "\n",
    "# Output files\n",
    "OUT_FIXTURES_CSV = \"/content/todays_games.csv\"\n",
    "OUT_TEAM_CSV     = \"/content/preds_team_only.csv\"\n",
    "OUT_LINES_CSV    = \"/content/preds_with_lines.csv\"\n",
    "OUT_HYBRID_CSV   = \"/content/preds_hybrid.csv\"\n",
    "\n",
    "# Hybrid blend weight (0..1). final_prob = (1-α)*team + α*with_lines\n",
    "HYBRID_ALPHA   = 0.60\n",
    "TEAM_THRESHOLD = 0.50\n",
    "\n",
    "# Cache path for precomputed team snapshots (speeds up daily runs)\n",
    "CACHE_TEAM_PARQUET = \"/content/cache_team_all.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 3) Imports & Helpers ===\n",
    "import pandas as pd, numpy as np, joblib, pytz, requests\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from nba_api.live.nba.endpoints import scoreboard as live_scoreboard\n",
    "\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "# ---- Odds/prob helpers ----\n",
    "def implied_prob(ml):\n",
    "    ml = pd.to_numeric(ml, errors=\"coerce\")\n",
    "    return np.where(ml < 0, -ml / (-ml + 100), 100 / (ml + 100))\n",
    "\n",
    "def moneyline_to_decimal(ml):\n",
    "    ml = pd.to_numeric(ml, errors=\"coerce\")\n",
    "    return np.where(ml < 0, 1 + 100/(-ml), 1 + ml/100)\n",
    "\n",
    "# ---- Team name mapping ----\n",
    "TEAM_ALIASES = {\n",
    "    \"Atlanta Hawks\":\"Atlanta Hawks\",\"Boston Celtics\":\"Boston Celtics\",\"Brooklyn Nets\":\"Brooklyn Nets\",\n",
    "    \"Charlotte Hornets\":\"Charlotte Hornets\",\"Chicago Bulls\":\"Chicago Bulls\",\"Cleveland Cavaliers\":\"Cleveland Cavaliers\",\n",
    "    \"Dallas Mavericks\":\"Dallas Mavericks\",\"Denver Nuggets\":\"Denver Nuggets\",\"Detroit Pistons\":\"Detroit Pistons\",\n",
    "    \"Golden State Warriors\":\"Golden State Warriors\",\"Houston Rockets\":\"Houston Rockets\",\"Indiana Pacers\":\"Indiana Pacers\",\n",
    "    \"Los Angeles Clippers\":\"Los Angeles Clippers\",\"Los Angeles Lakers\":\"Los Angeles Lakers\",\"Memphis Grizzlies\":\"Memphis Grizzlies\",\n",
    "    \"Miami Heat\":\"Miami Heat\",\"Milwaukee Bucks\":\"Milwaukee Bucks\",\"Minnesota Timberwolves\":\"Minnesota Timberwolves\",\n",
    "    \"New Orleans Pelicans\":\"New Orleans Pelicans\",\"New York Knicks\":\"New York Knicks\",\"Oklahoma City Thunder\":\"Oklahoma City Thunder\",\n",
    "    \"Orlando Magic\":\"Orlando Magic\",\"Philadelphia 76ers\":\"Philadelphia 76ers\",\"Phoenix Suns\":\"Phoenix Suns\",\n",
    "    \"Portland Trail Blazers\":\"Portland Trail Blazers\",\"Sacramento Kings\":\"Sacramento Kings\",\"San Antonio Spurs\":\"San Antonio Spurs\",\n",
    "    \"Toronto Raptors\":\"Toronto Raptors\",\"Utah Jazz\":\"Utah Jazz\",\"Washington Wizards\":\"Washington Wizards\",\n",
    "    # Nicknames -> Full\n",
    "    \"Celtics\":\"Boston Celtics\",\"Nets\":\"Brooklyn Nets\",\"Knicks\":\"New York Knicks\",\"76ers\":\"Philadelphia 76ers\",\"Sixers\":\"Philadelphia 76ers\",\n",
    "    \"Raptors\":\"Toronto Raptors\",\"Bulls\":\"Chicago Bulls\",\"Cavaliers\":\"Cleveland Cavaliers\",\"Cavs\":\"Cleveland Cavaliers\",\n",
    "    \"Pistons\":\"Detroit Pistons\",\"Pacers\":\"Indiana Pacers\",\"Bucks\":\"Milwaukee Bucks\",\"Hawks\":\"Atlanta Hawks\",\"Hornets\":\"Charlotte Hornets\",\n",
    "    \"Heat\":\"Miami Heat\",\"Magic\":\"Orlando Magic\",\"Wizards\":\"Washington Wizards\",\n",
    "    \"Nuggets\":\"Denver Nuggets\",\"Timberwolves\":\"Minnesota Timberwolves\",\"Wolves\":\"Minnesota Timberwolves\",\n",
    "    \"Jazz\":\"Utah Jazz\",\"Thunder\":\"Oklahoma City Thunder\",\"Trail Blazers\":\"Portland Trail Blazers\",\"Blazers\":\"Portland Trail Blazers\",\n",
    "    \"Warriors\":\"Golden State Warriors\",\"Clippers\":\"Los Angeles Clippers\",\"Lakers\":\"Los Angeles Lakers\",\n",
    "    \"Suns\":\"Phoenix Suns\",\"Kings\":\"Sacramento Kings\",\"Mavericks\":\"Dallas Mavericks\",\"Mavs\":\"Dallas Mavericks\",\n",
    "    \"Grizzlies\":\"Memphis Grizzlies\",\"Spurs\":\"San Antonio Spurs\",\"Pelicans\":\"New Orleans Pelicans\",\"Pels\":\"New Orleans Pelicans\",\n",
    "    \"Rockets\":\"Houston Rockets\",\n",
    "}\n",
    "\n",
    "def normalize_team(name: str) -> str:\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "    n = name.strip()\n",
    "    n = n.replace(\"LA Clippers\", \"Clippers\").replace(\"LA Lakers\", \"Lakers\")\n",
    "    return TEAM_ALIASES.get(n, TEAM_ALIASES.get(n.title(), n))\n",
    "\n",
    "# ---- Snapshot builders ----\n",
    "def make_team_frame(df):\n",
    "    home = df[[\"date\",\"home_team\",\"home_points\",\"away_points\"]].rename(\n",
    "        columns={\"home_team\":\"team\",\"home_points\":\"points_for\",\"away_points\":\"points_against\"}\n",
    "    ); home[\"is_home\"] = 1\n",
    "    away = df[[\"date\",\"away_team\",\"away_points\",\"home_points\"]].rename(\n",
    "        columns={\"away_team\":\"team\",\"away_points\":\"points_for\",\"home_points\":\"points_against\"}\n",
    "    ); away[\"is_home\"] = 0\n",
    "    team_df = pd.concat([home, away]).sort_values([\"team\",\"date\"]).reset_index(drop=True)\n",
    "    team_df[\"margin\"] = team_df[\"points_for\"] - team_df[\"points_against\"]\n",
    "    return team_df\n",
    "\n",
    "def add_rolls(team_df, windows=[3,5]):\n",
    "    grp = team_df.groupby(\"team\", group_keys=False)\n",
    "    team_df[\"games_played\"] = grp.cumcount()\n",
    "    for col in [\"points_for\",\"points_against\",\"margin\"]:\n",
    "        team_df[f\"{col}_exp\"] = grp[col].transform(lambda s: s.shift(1).expanding().mean())\n",
    "    for w in windows:\n",
    "        team_df[f\"pf_{w}g\"] = grp[\"points_for\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "        team_df[f\"pa_{w}g\"] = grp[\"points_against\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "        team_df[f\"margin_{w}g\"] = grp[\"margin\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "    team_df[\"rest_days\"] = grp[\"date\"].diff().dt.days\n",
    "    team_df[\"b2b\"] = (team_df[\"rest_days\"]==1).astype(float)\n",
    "    return team_df\n",
    "\n",
    "def latest_snapshot_before(snap_df, key_col, team, date_col, game_date):\n",
    "    snap = snap_df[(snap_df[key_col]==team) & (snap_df[date_col] < game_date)].sort_values(date_col).tail(1)\n",
    "    return snap\n",
    "\n",
    "# ---- Pickle-safe calibrated XGB wrapper (for loading saved models) ----\n",
    "class CalibratedXGB(BaseEstimator, ClassifierMixin):\n",
    "    _estimator_type = \"classifier\"\n",
    "    def __init__(self, base=None, platt=None): self.base, self.platt = base, platt\n",
    "    def fit(self, X, y): return self\n",
    "    def predict_proba(self, X):\n",
    "        p = self.base.predict_proba(X)[:,1]\n",
    "        pc = self.platt.predict_proba(p.reshape(-1,1))[:,1]\n",
    "        return np.column_stack([1-pc, pc])\n",
    "    def predict(self, X): return (self.predict_proba(X)[:,1] >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 4) Load history & build/cache team snapshots (fast with parquet cache) ===\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "hist = pd.read_csv(HIST_CSV, parse_dates=[\"date\"])\n",
    "hist = hist.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "if os.path.exists(CACHE_TEAM_PARQUET):\n",
    "    try:\n",
    "        team_all = pd.read_parquet(CACHE_TEAM_PARQUET)\n",
    "        # ensure types are right\n",
    "        team_all[\"HACK\"] = 1  # touch to validate\n",
    "        team_all = team_all.drop(columns=[\"HACK\"])\n",
    "        print(\"Loaded team snapshots from cache:\", CACHE_TEAM_PARQUET)\n",
    "    except Exception as e:\n",
    "        print(\"Cache read failed, rebuilding snapshots:\", e)\n",
    "        team_all = add_rolls(make_team_frame(hist), windows=[3,5])\n",
    "        team_all.to_parquet(CACHE_TEAM_PARQUET, index=False)\n",
    "        print(\"Cached snapshots to:\", CACHE_TEAM_PARQUET)\n",
    "else:\n",
    "    team_all = add_rolls(make_team_frame(hist), windows=[3,5])\n",
    "    try:\n",
    "        team_all.to_parquet(CACHE_TEAM_PARQUET, index=False)\n",
    "        print(\"Cached snapshots to:\", CACHE_TEAM_PARQUET)\n",
    "    except Exception as e:\n",
    "        print(\"Parquet cache save skipped:\", e)\n",
    "\n",
    "H_all = team_all[team_all[\"is_home\"]==1].add_prefix(\"H_\")\n",
    "A_all = team_all[team_all[\"is_home\"]==0].add_prefix(\"A_\")\n",
    "print(\"Snapshots ready. H rows:\", len(H_all), \"A rows:\", len(A_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 5) Fetch today's games + current lines (robust) ===\n",
    "import pandas as pd, numpy as np, requests, pytz\n",
    "from nba_api.live.nba.endpoints import scoreboard as live_scoreboard\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "REGIONS_TRY  = [\"us\", \"us2\", \"uk\", \"eu\", \"au\"]\n",
    "BOOK_PREF    = [\"fanduel\", \"draftkings\", \"betmgm\", \"caesars\", \"pointsbetus\", \"barstool\"]\n",
    "MARKETS      = \"h2h,spreads\"\n",
    "\n",
    "def iso_sec(dtobj):\n",
    "    return dtobj.astimezone(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "def today_et_date():\n",
    "    et = pytz.timezone(\"US/Eastern\")\n",
    "    return datetime.now(et).date()\n",
    "\n",
    "def odds_api(url, params):\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=15)\n",
    "        rem = r.headers.get(\"x-requests-remaining\")\n",
    "        used = r.headers.get(\"x-requests-used\")\n",
    "        print(f\"[odds-api] HTTP {r.status_code} | used={used} remaining={rem}\")\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print(\"[odds-api] Error:\", e)\n",
    "        return None\n",
    "\n",
    "def pick_book(books, market):\n",
    "    by_key = {b.get(\"key\"): b for b in (books or [])}\n",
    "    for bk in BOOK_PREF:\n",
    "        b = by_key.get(bk)\n",
    "        if not b: \n",
    "            continue\n",
    "        for m in b.get(\"markets\", []) or []:\n",
    "            if m.get(\"key\") == market:\n",
    "                return bk, m\n",
    "    for b in books or []:\n",
    "        for m in b.get(\"markets\", []) or []:\n",
    "            if m.get(\"key\") == market:\n",
    "                return b.get(\"key\"), m\n",
    "    return None, None\n",
    "\n",
    "def extract_moneylines(game_json):\n",
    "    key, m = pick_book(game_json.get(\"bookmakers\"), \"h2h\")\n",
    "    if not m: return None, None\n",
    "    out = m.get(\"outcomes\", []) or []\n",
    "    d = {normalize_team(o.get(\"name\")): o.get(\"price\") for o in out if \"name\" in o}\n",
    "    return d, key\n",
    "\n",
    "def extract_spreads(game_json):\n",
    "    key, m = pick_book(game_json.get(\"bookmakers\"), \"spreads\")\n",
    "    if not m: return None, None\n",
    "    out = m.get(\"outcomes\", []) or []\n",
    "    d = {normalize_team(o.get(\"name\")): o.get(\"point\") for o in out if \"name\" in o}\n",
    "    return d, key\n",
    "\n",
    "# 5a) Today's schedule\n",
    "today = today_et_date()\n",
    "print(\"Today (ET):\", today)\n",
    "sb = live_scoreboard.ScoreBoard()\n",
    "games = sb.games.get_dict()\n",
    "\n",
    "sched_rows = []\n",
    "for g in games:\n",
    "    hname = g[\"homeTeam\"].get(\"teamName\") or g[\"homeTeam\"].get(\"name\")\n",
    "    aname = g[\"awayTeam\"].get(\"teamName\") or g[\"awayTeam\"].get(\"name\")\n",
    "    h = normalize_team(hname); a = normalize_team(aname)\n",
    "    sched_rows.append({\"date\": pd.to_datetime(today), \"home_team\": h, \"away_team\": a})\n",
    "\n",
    "sched = pd.DataFrame(sched_rows).drop_duplicates()\n",
    "if sched.empty:\n",
    "    print(\"No NBA games found today via nba_api.\")\n",
    "    sched = pd.DataFrame(columns=[\"date\",\"home_team\",\"away_team\"])\n",
    "\n",
    "# 5b) Odds API (optional)\n",
    "moneyline_map, spread_map = {}, {}\n",
    "if ODDS_API_KEY:\n",
    "    base = \"https://api.the-odds-api.com/v4/sports/basketball_nba/odds\"\n",
    "    t0 = datetime.now(timezone.utc) - timedelta(hours=6)\n",
    "    t1 = datetime.now(timezone.utc) + timedelta(days=2)\n",
    "    t0s, t1s = iso_sec(t0), iso_sec(t1)\n",
    "\n",
    "    got_any = False\n",
    "    for region in REGIONS_TRY:\n",
    "        print(f\"\\n[odds-api] Query region='{region}' window {t0s} -> {t1s}\")\n",
    "        params = {\n",
    "            \"apiKey\": ODDS_API_KEY,\n",
    "            \"regions\": region,\n",
    "            \"markets\": MARKETS,\n",
    "            \"oddsFormat\": \"american\",\n",
    "            \"dateFormat\": \"iso\",\n",
    "            \"commenceTimeFrom\": t0s,\n",
    "            \"commenceTimeTo\":   t1s,\n",
    "        }\n",
    "        resp = odds_api(base, params)\n",
    "        if resp is None: \n",
    "            continue\n",
    "        if resp.status_code == 422:\n",
    "            print(\"[odds-api] 422 invalid commenceTime*. Retrying WITHOUT window...\")\n",
    "            params2 = {\n",
    "                \"apiKey\": ODDS_API_KEY,\n",
    "                \"regions\": region,\n",
    "                \"markets\": MARKETS,\n",
    "                \"oddsFormat\": \"american\",\n",
    "                \"dateFormat\": \"iso\",\n",
    "            }\n",
    "            resp = odds_api(base, params2)\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            if isinstance(data, list) and len(data) > 0:\n",
    "                print(f\"[odds-api] Found {len(data)} events in region '{region}'.\")\n",
    "                got_any = True\n",
    "                for game in data:\n",
    "                    home = normalize_team(game.get(\"home_team\"))\n",
    "                    away = normalize_team(game.get(\"away_team\"))\n",
    "                    ml_dict, _ = extract_moneylines(game)\n",
    "                    if ml_dict: moneyline_map[(home, away)] = ml_dict\n",
    "                    sp_dict, _ = extract_spreads(game)\n",
    "                    if sp_dict: spread_map[(home, away)] = sp_dict\n",
    "                break\n",
    "            else:\n",
    "                print(f\"[odds-api] 200 OK but no events returned for region '{region}'.\")\n",
    "        else:\n",
    "            print(f\"[odds-api] HTTP {resp.status_code}: {resp.text[:300]}\")\n",
    "else:\n",
    "    print(\"No ODDS_API_KEY set; continuing without odds.\")\n",
    "\n",
    "# 5c) Merge schedule + odds and save fixtures CSV\n",
    "def lookup_moneylines(h, a):\n",
    "    d = moneyline_map.get((h,a)) or moneyline_map.get((a,h))\n",
    "    if not d: return np.nan, np.nan\n",
    "    return d.get(h, np.nan), d.get(a, np.nan)\n",
    "\n",
    "def lookup_spread(h, a):\n",
    "    d = spread_map.get((h,a)) or spread_map.get((a,h))\n",
    "    if not d: return np.nan\n",
    "    return d.get(h, np.nan)\n",
    "\n",
    "if not sched.empty:\n",
    "    sched[\"home_moneyline\"], sched[\"away_moneyline\"] = zip(*[\n",
    "        lookup_moneylines(h, a) for h, a in zip(sched[\"home_team\"], sched[\"away_team\"])\n",
    "    ])\n",
    "    sched[\"spread_close\"] = [\n",
    "        lookup_spread(h, a) for h, a in zip(sched[\"home_team\"], sched[\"away_team\"])\n",
    "    ]\n",
    "\n",
    "for c in [\"home_moneyline\",\"away_moneyline\",\"spread_close\"]:\n",
    "    if c in sched.columns:\n",
    "        sched[c] = pd.to_numeric(sched[c], errors=\"coerce\")\n",
    "\n",
    "sched = sched.sort_values([\"date\",\"home_team\"]).reset_index(drop=True)\n",
    "sched.to_csv(OUT_FIXTURES_CSV, index=False)\n",
    "print(f\"\\nSaved {len(sched)} games to {OUT_FIXTURES_CSV}\")\n",
    "display(sched.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 6) Load models & feature lists ===\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "def load_models_safe(paths):\n",
    "    try:\n",
    "        return [joblib.load(p) for p in paths]\n",
    "    except Exception as e:\n",
    "        print(\"Model load error:\", e)\n",
    "        return [None, None, None]\n",
    "\n",
    "def load_featlist_safe(path):\n",
    "    try:\n",
    "        s = pd.read_csv(path, header=None).iloc[:,0].astype(str).str.strip().tolist()\n",
    "        return [c for c in s if c not in {\"\", \"0\", \"Unnamed: 0\"}]\n",
    "    except Exception as e:\n",
    "        print(\"Feature list load error:\", e)\n",
    "        return None\n",
    "\n",
    "team_lr, team_rf, team_xgb = load_models_safe([TEAM_LR_PATH, TEAM_RF_PATH, TEAM_XGB_PATH])\n",
    "team_feats = load_featlist_safe(TEAM_FEATS_CSV)\n",
    "print(f\"Team-only models loaded: {all(m is not None for m in [team_lr,team_rf,team_xgb])}, features: {len(team_feats) if team_feats else 0}\")\n",
    "\n",
    "lines_lr, lines_rf, lines_xgb = load_models_safe([LINES_LR_PATH, LINES_RF_PATH, LINES_XGB_PATH])\n",
    "lines_feats = load_featlist_safe(LINES_FEATS_CSV)\n",
    "print(f\"With-lines models loaded: {all(m is not None for m in [lines_lr,lines_rf,lines_xgb])}, features: {len(lines_feats) if lines_feats else 0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 7) Final Predictions (Team-only + With-lines + Hybrid) ===\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Build per-game base with full H_/A_ snapshots\n",
    "fx = pd.read_csv(OUT_FIXTURES_CSV, parse_dates=[\"date\"])\n",
    "rows, missing_hist = [], set()\n",
    "\n",
    "for _, r in fx.iterrows():\n",
    "    d, h, a = r[\"date\"], str(r[\"home_team\"]), str(r[\"away_team\"])\n",
    "    H_snap = latest_snapshot_before(H_all, \"H_team\", h, \"H_date\", d)\n",
    "    A_snap = latest_snapshot_before(A_all, \"A_team\", a, \"A_date\", d)\n",
    "    if H_snap.empty:\n",
    "        missing_hist.add(h); H_snap = pd.DataFrame([{c: np.nan for c in H_all.columns}]); H_snap[\"H_team\"]=h; H_snap[\"H_date\"]=pd.NaT\n",
    "    if A_snap.empty:\n",
    "        missing_hist.add(a); A_snap = pd.DataFrame([{c: np.nan for c in A_all.columns}]); A_snap[\"A_team\"]=a; A_snap[\"A_date\"]=pd.NaT\n",
    "\n",
    "    base = pd.DataFrame([{\"date\": d, \"home_team\": h, \"away_team\": a}])\n",
    "    merged = (base\n",
    "              .merge(H_snap, how=\"left\", left_on=\"home_team\", right_on=\"H_team\")\n",
    "              .merge(A_snap, how=\"left\", left_on=\"away_team\", right_on=\"A_team\"))\n",
    "    merged[\"rest_diff\"]   = merged[\"H_rest_days\"] - merged[\"A_rest_days\"]\n",
    "    merged[\"b2b_diff\"]    = merged[\"H_b2b\"] - merged[\"A_b2b\"]\n",
    "    merged[\"home_on_b2b\"] = merged[\"H_b2b\"]\n",
    "    merged[\"away_on_b2b\"] = merged[\"A_b2b\"]\n",
    "    # pass market fields for reporting and with-lines model\n",
    "    for c in [\"home_moneyline\",\"away_moneyline\",\"spread_close\"]:\n",
    "        if c in fx.columns: merged[c] = r.get(c, np.nan)\n",
    "    rows.append(merged)\n",
    "\n",
    "pred_base = pd.concat(rows, ignore_index=True)\n",
    "if missing_hist:\n",
    "    print(f\"Note: missing recent history for {len(missing_hist)} team(s): {sorted(missing_hist)} (features will be imputed).\")\n",
    "\n",
    "# Precompute market probs for reporting\n",
    "if \"home_moneyline\" in pred_base.columns and \"away_moneyline\" in pred_base.columns:\n",
    "    pred_base[\"home_imp_raw\"] = implied_prob(pred_base[\"home_moneyline\"])\n",
    "    pred_base[\"away_imp_raw\"] = implied_prob(pred_base[\"away_moneyline\"])\n",
    "    s = pred_base[\"home_imp_raw\"] + pred_base[\"away_imp_raw\"]\n",
    "    pred_base[\"market_prob_home\"] = pred_base[\"home_imp_raw\"] / s\n",
    "else:\n",
    "    pred_base[\"market_prob_home\"] = np.nan\n",
    "\n",
    "# ---- TEAM-ONLY predictions ----\n",
    "team_out = None\n",
    "if team_feats and all(m is not None for m in [team_lr,team_rf,team_xgb]):\n",
    "    Xt = pred_base.copy()\n",
    "    for c in team_feats:\n",
    "        if c not in Xt.columns: Xt[c] = np.nan\n",
    "    Xt = Xt[team_feats].replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "    p_lr  = team_lr.predict_proba(Xt)[:,1]\n",
    "    p_rf  = team_rf.predict_proba(Xt)[:,1]\n",
    "    p_xgb = team_xgb.predict_proba(Xt)[:,1]\n",
    "    p_ens = np.mean([p_lr, p_rf, p_xgb], axis=0)\n",
    "\n",
    "    pred_home = (p_ens >= TEAM_THRESHOLD).astype(int)\n",
    "    conf_team = np.where(pred_home==1, p_ens, 1 - p_ens)\n",
    "\n",
    "    team_out = pred_base[[\"date\",\"home_team\",\"away_team\"]].copy()\n",
    "    team_out[\"prob_home_ens_team\"] = p_ens\n",
    "    team_out[\"predicted_winner_team\"] = np.where(pred_home==1, team_out[\"home_team\"], team_out[\"away_team\"])\n",
    "    team_out[\"confidence_team\"] = conf_team\n",
    "    if \"home_moneyline\" in pred_base.columns:\n",
    "        team_out[\"winner_moneyline_team\"] = np.where(pred_home==1, pred_base[\"home_moneyline\"], pred_base[\"away_moneyline\"])\n",
    "    team_out[\"market_prob_home\"] = pred_base[\"market_prob_home\"].values\n",
    "    team_out = team_out.sort_values([\"date\",\"home_team\"]).reset_index(drop=True)\n",
    "    team_out.to_csv(OUT_TEAM_CSV, index=False)\n",
    "    print(f\"\\nSaved TEAM-ONLY predictions -> {OUT_TEAM_CSV}\")\n",
    "    display(team_out)\n",
    "\n",
    "# ---- WITH-LINES predictions ----\n",
    "lines_out = None\n",
    "if lines_feats and all(m is not None for m in [lines_lr,lines_rf,lines_xgb]):\n",
    "    Xl = pred_base.copy()\n",
    "    for c in lines_feats:\n",
    "        if c not in Xl.columns: Xl[c] = np.nan\n",
    "    Xl = Xl[lines_feats].replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "    pl_lr  = lines_lr.predict_proba(Xl)[:,1]\n",
    "    pl_rf  = lines_rf.predict_proba(Xl)[:,1]\n",
    "    pl_xgb = lines_xgb.predict_proba(Xl)[:,1]\n",
    "    p_ensl = np.mean([pl_lr, pl_rf, pl_xgb], axis=0)\n",
    "\n",
    "    pred_home_l = (p_ensl >= 0.5).astype(int)\n",
    "    conf_lines = np.where(pred_home_l==1, p_ensl, 1 - p_ensl)\n",
    "\n",
    "    lines_out = pred_base[[\"date\",\"home_team\",\"away_team\"]].copy()\n",
    "    lines_out[\"prob_home_ens_lines\"] = p_ensl\n",
    "    lines_out[\"predicted_winner_lines\"] = np.where(pred_home_l==1, lines_out[\"home_team\"], lines_out[\"away_team\"])\n",
    "    lines_out[\"confidence_lines\"] = conf_lines\n",
    "    for c in [\"home_moneyline\",\"away_moneyline\"]:\n",
    "        if c in pred_base.columns: lines_out[c] = pred_base[c].values\n",
    "    lines_out[\"winner_moneyline_lines\"] = np.where(pred_home_l==1, lines_out[\"home_moneyline\"], lines_out[\"away_moneyline\"])\n",
    "    lines_out[\"market_prob_home\"] = pred_base[\"market_prob_home\"].values\n",
    "    lines_out = lines_out.sort_values([\"date\",\"home_team\"]).reset_index(drop=True)\n",
    "    lines_out.to_csv(OUT_LINES_CSV, index=False)\n",
    "    print(f\"\\nSaved WITH-LINES predictions -> {OUT_LINES_CSV}\")\n",
    "    display(lines_out)\n",
    "\n",
    "# ---- HYBRID blend ----\n",
    "if (team_out is not None) and (lines_out is not None):\n",
    "    hybrid = pred_base[[\"date\",\"home_team\",\"away_team\"]].copy()\n",
    "    hybrid[\"prob_home_team\"]  = team_out[\"prob_home_ens_team\"].values\n",
    "    hybrid[\"prob_home_lines\"] = lines_out[\"prob_home_ens_lines\"].values\n",
    "    hybrid[\"prob_home_hybrid\"] = (1 - HYBRID_ALPHA)*hybrid[\"prob_home_team\"] + HYBRID_ALPHA*hybrid[\"prob_home_lines\"]\n",
    "    pred_home_h = (hybrid[\"prob_home_hybrid\"] >= 0.5).astype(int)\n",
    "    hybrid[\"predicted_winner_hybrid\"] = np.where(pred_home_h==1, pred_base[\"home_team\"], pred_base[\"away_team\"])\n",
    "    hybrid[\"confidence_hybrid\"] = np.where(pred_home_h==1, hybrid[\"prob_home_hybrid\"], 1 - hybrid[\"prob_home_hybrid\"])\n",
    "    for c in [\"home_moneyline\",\"away_moneyline\"]:\n",
    "        if c in pred_base.columns: hybrid[c] = pred_base[c].values\n",
    "    hybrid[\"winner_moneyline_hybrid\"] = np.where(pred_home_h==1, hybrid[\"home_moneyline\"], hybrid[\"away_moneyline\"])\n",
    "    hybrid = hybrid.sort_values([\"date\",\"home_team\"]).reset_index(drop=True)\n",
    "    hybrid.to_csv(OUT_HYBRID_CSV, index=False)\n",
    "    print(f\"\\nSaved HYBRID predictions -> {OUT_HYBRID_CSV}\")\n",
    "    display(hybrid)\n",
    "elif team_out is not None:\n",
    "    print(\"\\nHybrid skipped (with-lines models unavailable).\")\n",
    "elif lines_out is not None:\n",
    "    print(\"\\nHybrid skipped (team-only models unavailable).\")\n",
    "else:\n",
    "    print(\"\\nNo models available to predict.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
