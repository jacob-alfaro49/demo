{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "dbOIYeRoco06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['ODDS_API_KEY'] = '1dc699f4866af6cf86156c64bf5b511b'"
      ],
      "metadata": {
        "id": "MneTodBTbFzX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "!pip -q install xgboost==2.0.3 scikit-learn pandas numpy matplotlib\n",
        "import json, zipfile, io, pandas as pd, numpy as np\n",
        "from datetime import datetime, timezone\n",
        "from dateutil.parser import isoparse\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, brier_score_loss\n",
        "from sklearn.base import clone\n",
        "from sklearn.linear_model import LogisticRegression as PlattLR\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmUmOy_oKZEW",
        "outputId": "251cd079-71da-4b87-96da-c6911a9388c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models\n"
      ],
      "metadata": {
        "id": "8d6qUIp6chkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run models and save lr_cal, rf_cal, xgb_cal"
      ],
      "metadata": {
        "id": "7te5EM2NduCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Adjust if betting lines are used to train\n",
        "USE_BETTING_LINES = True\n",
        "\n",
        "#  Load dataset\n",
        "HISTORICAL_CSV = \"/content/nba_games_with_odds_2010on.csv\"\n",
        "games = pd.read_csv(HISTORICAL_CSV, parse_dates=[\"date\"])\n",
        "games = games.sort_values(\"date\").reset_index(drop=True)\n",
        "games[\"home_win\"] = (games[\"home_points\"] > games[\"away_points\"]).astype(int)\n",
        "\n",
        "#  Split data\n",
        "cutoff_date = games[\"date\"].quantile(0.8)\n",
        "train_games = games[games[\"date\"] < cutoff_date].copy()\n",
        "valid_games = games[games[\"date\"] >= cutoff_date].copy()\n",
        "print(f\"Train games: {len(train_games)}, Valid games: {len(valid_games)}, cutoff: {cutoff_date.date()}\")\n",
        "\n",
        "#  Rolling features\n",
        "def make_team_frame(df):\n",
        "    home = df[[\"date\",\"home_team\",\"home_points\",\"away_points\"]].rename(\n",
        "        columns={\"home_team\":\"team\",\"home_points\":\"points_for\",\"away_points\":\"points_against\"}\n",
        "    ); home[\"is_home\"]=1\n",
        "    away = df[[\"date\",\"away_team\",\"away_points\",\"home_points\"]].rename(\n",
        "        columns={\"away_team\":\"team\",\"away_points\":\"points_for\",\"home_points\":\"points_against\"}\n",
        "    ); away[\"is_home\"]=0\n",
        "    team_df = pd.concat([home,away]).sort_values([\"team\",\"date\"]).reset_index(drop=True)\n",
        "    team_df[\"margin\"] = team_df[\"points_for\"] - team_df[\"points_against\"]\n",
        "    return team_df\n",
        "\n",
        "def add_rolls(team_df, windows=[3,5]):\n",
        "    grp = team_df.groupby(\"team\", group_keys=False)\n",
        "    team_df[\"games_played\"] = grp.cumcount()\n",
        "    for col in [\"points_for\",\"points_against\",\"margin\"]:\n",
        "        team_df[f\"{col}_exp\"] = grp[col].transform(lambda s: s.shift(1).expanding().mean())\n",
        "    for w in windows:\n",
        "        team_df[f\"pf_{w}g\"] = grp[\"points_for\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
        "        team_df[f\"pa_{w}g\"] = grp[\"points_against\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
        "        team_df[f\"margin_{w}g\"] = grp[\"margin\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
        "    team_df[\"rest_days\"] = grp[\"date\"].diff().dt.days\n",
        "    team_df[\"b2b\"] = (team_df[\"rest_days\"]==1).astype(float)\n",
        "    return team_df\n",
        "\n",
        "#  Adds rest/travel\n",
        "def build_leakproof_features(train_games, valid_games, windows=[3,5]):\n",
        "    all_games = pd.concat([train_games, valid_games]).sort_values(\"date\").reset_index(drop=True)\n",
        "    all_games[\"home_win\"] = (all_games[\"home_points\"] > all_games[\"away_points\"]).astype(int)\n",
        "\n",
        "    team_df = make_team_frame(all_games)\n",
        "    team_df = add_rolls(team_df, windows=windows)\n",
        "\n",
        "    H = team_df[team_df[\"is_home\"]==1].add_prefix(\"H_\")\n",
        "    A = team_df[team_df[\"is_home\"]==0].add_prefix(\"A_\")\n",
        "\n",
        "    full = (all_games\n",
        "            .merge(H, left_on=[\"date\",\"home_team\"], right_on=[\"H_date\",\"H_team\"], how=\"left\")\n",
        "            .merge(A, left_on=[\"date\",\"away_team\"], right_on=[\"A_date\",\"A_team\"], how=\"left\"))\n",
        "\n",
        "    full[\"rest_diff\"] = full[\"H_rest_days\"] - full[\"A_rest_days\"]\n",
        "    full[\"b2b_diff\"]  = full[\"H_b2b\"] - full[\"A_b2b\"]\n",
        "    full[\"home_on_b2b\"] = full[\"H_b2b\"]\n",
        "    full[\"away_on_b2b\"] = full[\"A_b2b\"]\n",
        "\n",
        "    num_cols = full.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    y = full[\"home_win\"].values\n",
        "    drop_target = [\"home_points\",\"away_points\",\"home_win\"]\n",
        "    features = [c for c in num_cols if c not in drop_target]\n",
        "\n",
        "    valid_start = valid_games[\"date\"].min()\n",
        "    X_train = full.loc[full[\"date\"] < valid_start, features].replace([np.inf,-np.inf], np.nan)\n",
        "    y_train = y[full[\"date\"] < valid_start]\n",
        "    X_valid = full.loc[full[\"date\"] >= valid_start, features].replace([np.inf,-np.inf], np.nan)\n",
        "    y_valid = y[full[\"date\"] >= valid_start]\n",
        "\n",
        "    return full, X_train, y_train, X_valid, y_valid\n",
        "\n",
        "full_base, X_train, y_train, X_valid, y_valid = build_leakproof_features(train_games, valid_games, windows=[3,5])\n",
        "\n",
        "#  Drop all-NaN columns\n",
        "nan_cols = X_train.columns[X_train.isna().all()].tolist()\n",
        "if nan_cols:\n",
        "    print(f\"Dropping {len(nan_cols)} all-NaN columns:\", nan_cols[:8], \"...\")\n",
        "    X_train = X_train.drop(columns=nan_cols)\n",
        "    X_valid = X_valid.drop(columns=[c for c in nan_cols if c in X_valid.columns])\n",
        "\n",
        "# Add or drop bet lines\n",
        "line_cols = [\"spread_close\",\"home_moneyline\",\"away_moneyline\"]\n",
        "if not USE_BETTING_LINES:\n",
        "    X_train = X_train.drop(columns=[c for c in line_cols if c in X_train.columns], errors=\"ignore\")\n",
        "    X_valid = X_valid.drop(columns=[c for c in line_cols if c in X_valid.columns], errors=\"ignore\")\n",
        "    print(\"Betting lines dropped for evaluation.\")\n",
        "else:\n",
        "    kept = [c for c in line_cols if c in X_train.columns]\n",
        "    print(\"Betting lines kept for production:\", kept)\n",
        "\n",
        "#  Drop direct outcome columns\n",
        "leak_like = [c for c in X_train.columns if any(k in c.lower() for k in [\"margin\",\"points_for\",\"points_against\"])]\n",
        "if leak_like:\n",
        "    print(f\"Dropping {len(leak_like)} direct outcome columns:\", leak_like[:10], \"...\")\n",
        "    X_train = X_train.drop(columns=leak_like, errors=\"ignore\")\n",
        "    X_valid = X_valid.drop(columns=[c for c in leak_like if c in X_valid.columns], errors=\"ignore\")\n",
        "else:\n",
        "    print(\"No direct outcome columns found.\")\n",
        "\n",
        "#  Auto-detect any remaining perfect-correlation leaks\n",
        "for name, X, y in [(\"train\", X_train, y_train), (\"valid\", X_valid, y_valid)]:\n",
        "    corrs = pd.concat([pd.Series(y, name=\"home_win\"), X], axis=1)\\\n",
        "               .corr(numeric_only=True)[\"home_win\"].abs().sort_values(ascending=False)\n",
        "    perfect = [c for c in corrs.index if c != \"home_win\" and corrs[c] >= 0.9999]\n",
        "    if perfect:\n",
        "        print(f\"Perfect-correlation leak columns in {name} set:\", perfect)\n",
        "        X_train = X_train.drop(columns=perfect, errors=\"ignore\")\n",
        "        X_valid = X_valid.drop(columns=perfect, errors=\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NrpiLN8PbNJ",
        "outputId": "666187ed-f195-4bb2-9dec-0db2495fa1ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train games: 12691, Valid games: 3175, cutoff: 2020-09-07\n",
            "Betting lines kept for production: ['spread_close', 'home_moneyline', 'away_moneyline']\n",
            "Dropping 16 direct outcome columns: ['H_points_for', 'H_points_against', 'H_margin', 'H_points_for_exp', 'H_points_against_exp', 'H_margin_exp', 'H_margin_3g', 'H_margin_5g', 'A_points_for', 'A_points_against'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Models\n",
        "lr_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scale\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))\n",
        "])\n",
        "rf_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        n_estimators=600, max_depth=None, min_samples_leaf=2,\n",
        "        random_state=42, n_jobs=-1))\n",
        "])\n",
        "xgb_base = XGBClassifier(\n",
        "    n_estimators=600, learning_rate=0.05, max_depth=6,\n",
        "    subsample=0.9, colsample_bytree=0.9,\n",
        "    reg_lambda=1.0, random_state=42, eval_metric=\"logloss\",\n",
        "    tree_method=\"hist\", use_label_encoder=False\n",
        ")\n",
        "\n",
        "#  Calibrate\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "def fit_and_calibrate(estimator, name):\n",
        "    cal = CalibratedClassifierCV(estimator, method=\"sigmoid\", cv=tscv)\n",
        "    cal.fit(X_train, y_train)\n",
        "    print(f\"{name} fitted & calibrated.\")\n",
        "    return cal\n",
        "\n",
        "def fit_xgb_with_platt(model, X, y, cv):\n",
        "    oof = np.zeros(len(X), dtype=float)\n",
        "    for tr_idx, va_idx in cv.split(X):\n",
        "        Xm, Xv, ym, yv = X.iloc[tr_idx], X.iloc[va_idx], y[tr_idx], y[va_idx]\n",
        "        m = clone(model); m.fit(Xm, ym)\n",
        "        oof[va_idx] = m.predict_proba(Xv)[:,1]\n",
        "    platt = PlattLR(max_iter=1000); platt.fit(oof.reshape(-1,1), y)\n",
        "    model.fit(X, y)\n",
        "    class CalibratedXGB:\n",
        "        def __init__(self, base, platt): self.base, self.platt = base, platt\n",
        "        def predict_proba(self, X):\n",
        "            p = self.base.predict_proba(X)[:,1]\n",
        "            pc = self.platt.predict_proba(p.reshape(-1,1))[:,1]\n",
        "            return np.column_stack([1-pc, pc])\n",
        "    print(\"XGBoost fitted & Platt-calibrated.\")\n",
        "    return CalibratedXGB(model, platt)\n",
        "\n",
        "lr_cal  = fit_and_calibrate(lr_pipe, \"Logistic Regression\")\n",
        "rf_cal  = fit_and_calibrate(rf_pipe, \"Random Forest\")\n",
        "xgb_cal = fit_xgb_with_platt(xgb_base, X_train, y_train, tscv)\n",
        "\n",
        "#  Evaluation\n",
        "def evaluate(model, X, y):\n",
        "    p = model.predict_proba(X)[:,1]\n",
        "    pred = (p >= 0.5).astype(int)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y, pred),\n",
        "        \"log_loss\": log_loss(y, p, labels=[0,1]),\n",
        "        \"brier\": brier_score_loss(y, p),\n",
        "        \"roc_auc\": roc_auc_score(y, p),\n",
        "    }, p\n",
        "\n",
        "models = [(\"LR\", lr_cal), (\"RF\", rf_cal), (\"XGB\", xgb_cal)]\n",
        "preds = {}\n",
        "for name, model in models:\n",
        "    metrics, p = evaluate(model, X_valid, y_valid)\n",
        "    preds[name] = p\n",
        "    print(f\"\\n{name} metrics:\")\n",
        "    for k,v in metrics.items():\n",
        "        print(f\"  {k:>8}: {v:.4f}\")\n",
        "\n",
        "#  Soft-vote ensemble\n",
        "p_ens = np.mean(list(preds.values()), axis=0)\n",
        "pred_ens = (p_ens >= 0.5).astype(int)\n",
        "conf = np.where(pred_ens == 1, p_ens, 1 - p_ens)\n",
        "ens_metrics = {\n",
        "    \"accuracy\": accuracy_score(y_valid, pred_ens),\n",
        "    \"log_loss\": log_loss(y_valid, p_ens, labels=[0,1]),\n",
        "    \"brier\": brier_score_loss(y_valid, p_ens),\n",
        "    \"roc_auc\": roc_auc_score(y_valid, p_ens),\n",
        "}\n",
        "print(\"\\nEnsemble metrics:\")\n",
        "for k,v in ens_metrics.items():\n",
        "    print(f\"  {k:>8}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUJmt0JnUHu2",
        "outputId": "7c1347f5-73cd-4f30-e045-e156df88f5cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression fitted & calibrated.\n",
            "Random Forest fitted & calibrated.\n",
            "XGBoost fitted & Platt-calibrated.\n",
            "\n",
            "LR metrics:\n",
            "  accuracy: 0.6595\n",
            "  log_loss: 0.6284\n",
            "     brier: 0.2194\n",
            "   roc_auc: 0.7004\n",
            "\n",
            "RF metrics:\n",
            "  accuracy: 0.6419\n",
            "  log_loss: 0.6378\n",
            "     brier: 0.2234\n",
            "   roc_auc: 0.6826\n",
            "\n",
            "XGB metrics:\n",
            "  accuracy: 0.5868\n",
            "  log_loss: 0.6610\n",
            "     brier: 0.2344\n",
            "   roc_auc: 0.6668\n",
            "\n",
            "Ensemble metrics:\n",
            "  accuracy: 0.6532\n",
            "  log_loss: 0.6313\n",
            "     brier: 0.2203\n",
            "   roc_auc: 0.6997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "2MIIGS03Csm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Predictions using new season data (rolling features) +  betting lines for today ===\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "SEASON_CSV   = \"/content/2025_season_data.csv\"\n",
        "\n",
        "FIXTURES_CSV = \"/content/todays_games.csv\"\n",
        "\n",
        "USE_BETTING_LINES = True\n",
        "\n",
        "FALLBACK_HISTORICAL_CSV = \"/content/nba_games_with_odds_2010on.csv\"\n",
        "\n",
        "#  HELPERS\n",
        "def _pick(cols, candidates):\n",
        "    for c in candidates:\n",
        "        if c in cols: return c\n",
        "    return None\n",
        "\n",
        "try:\n",
        "    make_team_frame\n",
        "    add_rolls\n",
        "except NameError:\n",
        "    def make_team_frame(df):\n",
        "        home = df[[\"date\",\"home_team\",\"home_points\",\"away_points\"]].rename(\n",
        "            columns={\"home_team\":\"team\",\"home_points\":\"points_for\",\"away_points\":\"points_against\"}\n",
        "        ); home[\"is_home\"]=1\n",
        "        away = df[[\"date\",\"away_team\",\"away_points\",\"home_points\"]].rename(\n",
        "            columns={\"away_team\":\"team\",\"away_points\":\"points_for\",\"home_points\":\"points_against\"}\n",
        "        ); away[\"is_home\"]=0\n",
        "        team_df = pd.concat([home,away]).sort_values([\"team\",\"date\"]).reset_index(drop=True)\n",
        "        team_df[\"margin\"] = team_df[\"points_for\"] - team_df[\"points_against\"]\n",
        "        return team_df\n",
        "\n",
        "    def add_rolls(team_df, windows=[3,5]):\n",
        "        grp = team_df.groupby(\"team\", group_keys=False)\n",
        "        team_df[\"games_played\"] = grp.cumcount()\n",
        "        for col in [\"points_for\",\"points_against\",\"margin\"]:\n",
        "            team_df[f\"{col}_exp\"] = grp[col].transform(lambda s: s.shift(1).expanding().mean())\n",
        "        for w in windows:\n",
        "            team_df[f\"pf_{w}g\"] = grp[\"points_for\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
        "            team_df[f\"pa_{w}g\"] = grp[\"points_against\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
        "            team_df[f\"margin_{w}g\"] = grp[\"margin\"].transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
        "        team_df[\"rest_days\"] = grp[\"date\"].diff().dt.days\n",
        "        team_df[\"b2b\"] = (team_df[\"rest_days\"]==1).astype(float)\n",
        "        return team_df\n",
        "\n",
        "#  Load historical data\n",
        "hist = pd.read_csv(FALLBACK_HISTORICAL_CSV, parse_dates=[\"date\"])\n",
        "# ensure cols exist\n",
        "assert all(c in hist.columns for c in [\"date\",\"home_team\",\"away_team\",\"home_points\",\"away_points\"]), \\\n",
        "    f\"Historical CSV missing required columns: {hist.columns.tolist()}\"\n",
        "\n",
        "season_raw = pd.read_csv(SEASON_CSV)\n",
        "#  column mapping for season file\n",
        "cols = [c.lower() for c in season_raw.columns]\n",
        "date_col = _pick(season_raw.columns, [\"date\",\"game_date\"])\n",
        "home_col = _pick(season_raw.columns, [\"home_team\",\"home\"])\n",
        "away_col = _pick(season_raw.columns, [\"away_team\",\"away\"])\n",
        "hp_col   = _pick(season_raw.columns, [\"home_points\",\"home_pts\",\"home_score\"])\n",
        "ap_col   = _pick(season_raw.columns, [\"away_points\",\"away_pts\",\"away_score\"])\n",
        "\n",
        "assert date_col and home_col and away_col and hp_col and ap_col, \\\n",
        "    f\"Season CSV must include date/home_team/away_team/home_points/away_points. Found: {season_raw.columns.tolist()}\"\n",
        "\n",
        "season = season_raw.rename(columns={\n",
        "    date_col:\"date\", home_col:\"home_team\", away_col:\"away_team\",\n",
        "    hp_col:\"home_points\", ap_col:\"away_points\"\n",
        "})\n",
        "season[\"date\"] = pd.to_datetime(season[\"date\"])\n",
        "season = season.sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "# merge: append season results to hist, drop duplicates\n",
        "hist = pd.concat([hist, season], ignore_index=True)\n",
        "hist = hist.sort_values(\"date\").drop_duplicates(subset=[\"date\",\"home_team\",\"away_team\"], keep=\"last\").reset_index(drop=True)\n",
        "\n",
        "team_df_all = make_team_frame(hist)\n",
        "team_df_all = add_rolls(team_df_all, windows=[3,5])\n",
        "H_all = team_df_all[team_df_all[\"is_home\"]==1].add_prefix(\"H_\")\n",
        "A_all = team_df_all[team_df_all[\"is_home\"]==0].add_prefix(\"A_\")\n",
        "\n",
        "#  Load fixtures\n",
        "fixtures = pd.read_csv(FIXTURES_CSV)\n",
        "date_col = _pick(fixtures.columns, [\"date\",\"game_date\"])\n",
        "home_col = _pick(fixtures.columns, [\"home_team\",\"home\"])\n",
        "away_col = _pick(fixtures.columns, [\"away_team\",\"away\"])\n",
        "assert date_col and home_col and away_col, \\\n",
        "    f\"Fixtures CSV must include date/home_team/away_team. Found: {fixtures.columns.tolist()}\"\n",
        "\n",
        "fixtures = fixtures.rename(columns={date_col:\"date\", home_col:\"home_team\", away_col:\"away_team\"})\n",
        "fixtures[\"date\"] = pd.to_datetime(fixtures[\"date\"])\n",
        "fixtures = fixtures.sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "maybe_lines = {}\n",
        "for c in [\"spread_close\",\"home_moneyline\",\"away_moneyline\"]:\n",
        "    if c in fixtures.columns:\n",
        "        maybe_lines[c] = c\n",
        "\n",
        "# Build features\n",
        "records = []\n",
        "missing_hist = set()\n",
        "\n",
        "for _, row in fixtures.iterrows():\n",
        "    d, h, a = row[\"date\"], str(row[\"home_team\"]), str(row[\"away_team\"])\n",
        "    H_snap = H_all[(H_all[\"H_team\"]==h) & (H_all[\"H_date\"] < d)].sort_values(\"H_date\").tail(1)\n",
        "    A_snap = A_all[(A_all[\"A_team\"]==a) & (A_all[\"A_date\"] < d)].sort_values(\"A_date\").tail(1)\n",
        "\n",
        "    if H_snap.empty: missing_hist.add(h)\n",
        "    if A_snap.empty: missing_hist.add(a)\n",
        "\n",
        "    if H_snap.empty:\n",
        "        H_snap = pd.DataFrame([{c: np.nan for c in H_all.columns}]); H_snap[\"H_team\"]=h; H_snap[\"H_date\"]=pd.NaT\n",
        "    if A_snap.empty:\n",
        "        A_snap = pd.DataFrame([{c: np.nan for c in A_all.columns}]); A_snap[\"A_team\"]=a; A_snap[\"A_date\"]=pd.NaT\n",
        "\n",
        "    base = pd.DataFrame([\n",
        "        {\n",
        "            \"date\": d, \"home_team\": h, \"away_team\": a,\n",
        "            **{k: row[k] for k in maybe_lines}\n",
        "        }\n",
        "    ])\n",
        "\n",
        "    merged = (base\n",
        "              .merge(H_snap, how=\"left\", left_on=[\"home_team\"], right_on=[\"H_team\"])\n",
        "              .merge(A_snap, how=\"left\", left_on=[\"away_team\"], right_on=[\"A_team\"]))\n",
        "\n",
        "    # derived rest/travel features\n",
        "    merged[\"rest_diff\"]   = merged[\"H_rest_days\"] - merged[\"A_rest_days\"]\n",
        "    merged[\"b2b_diff\"]    = merged[\"H_b2b\"] - merged[\"A_b2b\"]\n",
        "    merged[\"home_on_b2b\"] = merged[\"H_b2b\"]\n",
        "    merged[\"away_on_b2b\"] = merged[\"A_b2b\"]\n",
        "    records.append(merged)\n",
        "\n",
        "pred_base = pd.concat(records, ignore_index=True)\n",
        "\n",
        "if missing_hist:\n",
        "    print(f\"Note: no recent history for {len(missing_hist)} team(s): {sorted(missing_hist)}; features will be imputed.\")\n",
        "\n",
        "assert 'X_train' in globals(), \"Expected X_train from training cell for feature alignment.\"\n",
        "feat_cols = X_train.columns.tolist()\n",
        "X_pred = pred_base.copy()\n",
        "\n",
        "# drop outcome-like fields if present\n",
        "drop_like = [c for c in X_pred.columns if any(k in c.lower() for k in [\"margin\",\"points_for\",\"points_against\",\"home_points\",\"away_points\",\"home_win\"])]\n",
        "if drop_like: X_pred = X_pred.drop(columns=drop_like, errors=\"ignore\")\n",
        "\n",
        "# include/exclude betting lines to match training usage\n",
        "if not USE_BETTING_LINES:\n",
        "    for c in [\"spread_close\",\"home_moneyline\",\"away_moneyline\"]:\n",
        "        if c in X_pred.columns:\n",
        "            X_pred = X_pred.drop(columns=c)\n",
        "\n",
        "# add any missing training columns as NaN\n",
        "for col in feat_cols:\n",
        "    if col not in X_pred.columns:\n",
        "        X_pred[col] = np.nan\n",
        "X_pred = X_pred[feat_cols].replace([np.inf,-np.inf], np.nan)\n"
      ],
      "metadata": {
        "id": "ptvnAymJCvZy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using fitted models\n",
        "assert all(v in globals() for v in [\"lr_cal\",\"rf_cal\",\"xgb_cal\"]), \\\n",
        "    \"Run the training cell first to create lr_cal, rf_cal, xgb_cal.\"\n",
        "\n",
        "p_lr  = lr_cal.predict_proba(X_pred)[:,1]\n",
        "p_rf  = rf_cal.predict_proba(X_pred)[:,1]\n",
        "p_xgb = xgb_cal.predict_proba(X_pred)[:,1]\n",
        "p_ens = np.mean([p_lr, p_rf, p_xgb], axis=0)\n",
        "\n",
        "pred_home = (p_ens >= 0.5).astype(int)\n",
        "confidence = np.where(pred_home==1, p_ens, 1 - p_ens)\n",
        "\n",
        "#  Output\n",
        "out = pred_base[[\"date\",\"home_team\",\"away_team\"]].copy()\n",
        "\n",
        "# model probabilities\n",
        "out[\"prob_home_LR\"]  = p_lr\n",
        "out[\"prob_home_RF\"]  = p_rf\n",
        "out[\"prob_home_XGB\"] = p_xgb\n",
        "out[\"prob_home_ens\"] = p_ens\n",
        "\n",
        "# predicted winner + confidence\n",
        "out[\"predicted_winner\"] = np.where(pred_home==1, out[\"home_team\"], out[\"away_team\"])\n",
        "out[\"confidence\"] = confidence\n",
        "\n",
        "# add moneyline for predicted winner\n",
        "if \"home_moneyline\" in pred_base.columns and \"away_moneyline\" in pred_base.columns:\n",
        "    out[\"winner_moneyline\"] = np.where(\n",
        "        pred_home==1,\n",
        "        pred_base[\"home_moneyline\"],\n",
        "        pred_base[\"away_moneyline\"]\n",
        "    )\n",
        "else:\n",
        "    out[\"winner_moneyline\"] = np.nan  # fill if odds not provided\n",
        "\n",
        "\n",
        "pd.options.display.float_format = \"{:.3f}\".format\n",
        "out = out.sort_values([\"date\",\"home_team\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nPredictions:\")\n",
        "print(out[[\"date\",\"home_team\",\"away_team\",\n",
        "           \"prob_home_LR\", \"prob_home_RF\", \"prob_home_XGB\",\n",
        "           \"predicted_winner\",\"confidence\",\"winner_moneyline\",\n",
        "           \"prob_home_ens\"]])\n",
        "\n",
        "SAVE_PATH = \"/content/todays_predictions.csv\"\n",
        "out.to_csv(SAVE_PATH, index=False)\n",
        "print(f\"\\nSaved predictions (with moneylines) to {SAVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6bA_k2MT-C1",
        "outputId": "1b168605-5e15-4832-de6c-ee73a391da2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions:\n",
            "        date               home_team              away_team  prob_home_LR  \\\n",
            "0 2025-11-17     Cleveland Cavaliers        Milwaukee Bucks         0.610   \n",
            "1 2025-11-17          Denver Nuggets          Chicago Bulls         0.853   \n",
            "2 2025-11-17         Detroit Pistons         Indiana Pacers         0.734   \n",
            "3 2025-11-17              Miami Heat        New York Knicks         0.501   \n",
            "4 2025-11-17  Minnesota Timberwolves       Dallas Mavericks         0.835   \n",
            "5 2025-11-17    New Orleans Pelicans  Oklahoma City Thunder         0.102   \n",
            "6 2025-11-17      Philadelphia 76ers   Los Angeles Clippers         0.720   \n",
            "7 2025-11-17         Toronto Raptors      Charlotte Hornets         0.778   \n",
            "\n",
            "   prob_home_RF  prob_home_XGB        predicted_winner  confidence  \\\n",
            "0         0.585          0.675     Cleveland Cavaliers       0.623   \n",
            "1         0.686          0.687          Denver Nuggets       0.742   \n",
            "2         0.626          0.658         Detroit Pistons       0.673   \n",
            "3         0.576          0.592              Miami Heat       0.556   \n",
            "4         0.741          0.697  Minnesota Timberwolves       0.758   \n",
            "5         0.290          0.474   Oklahoma City Thunder       0.711   \n",
            "6         0.667          0.674      Philadelphia 76ers       0.687   \n",
            "7         0.655          0.656         Toronto Raptors       0.696   \n",
            "\n",
            "   winner_moneyline  prob_home_ens  \n",
            "0              -270          0.623  \n",
            "1              -950          0.742  \n",
            "2              -520          0.673  \n",
            "3              -124          0.556  \n",
            "4              -900          0.758  \n",
            "5             -2500          0.289  \n",
            "6              -200          0.687  \n",
            "7              -370          0.696  \n",
            "\n",
            "Saved predictions (with moneylines) to /content/todays_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}